# ğŸ“˜ Polynomial Regression with Regularization (Ridge & Lasso)

## âœ… Overview

Real-world datasets are often **non-linear**, meaning a straight line (Linear Regression) cannot properly capture the pattern.

â¡ï¸ **Polynomial Regression** helps model non-linear relationships  
â¡ï¸ **Regularization (Ridge / Lasso)** prevents overfitting

---

## â­ What is Polynomial Regression?

Polynomial Regression transforms the original input **X** into higher-degree polynomial terms:

Example:  
For input feature `x`, polynomial regression generates:

| Degree | Features Generated |
|--------|-------------------|
| 1      | 1, x              |
| 2      | 1, x, xÂ²           |
| 3      | 1, x, xÂ², xÂ³       |

Thus, the model becomes:

\[
y = b_0 + b_1x + b_2x^2 + b_3x^3 + ... 
\]

ğŸ“Œ Even though equation becomes polynomial, we still use **Linear Regression internally**.

---

## âš ï¸ Problem: Overfitting

When polynomial degree increases (example: degree = 5 or 10), the model:

- fits the training data perfectly
- learns noise instead of real patterns

â— Result: **Training accuracy high, test accuracy low**

---

## âœ… Solution: Regularization

Regularization controls the **magnitude of model coefficients** so that the model does not become overly complex.

---

# ğŸ”¹ Ridge Regression (L2 Regularization)

> **â€œReduce coefficient magnitude, but donâ€™t eliminate features.â€**

Ridge adds a penalty on squared coefficients:

\[
Loss = MSE + \alpha \sum w^2
\]

- `Î»` (alpha) controls regularization strength
- Higher Î» â†’ more penalty â†’ coefficients shrink

âœ… Prevents overfitting  
âŒ Does not remove features (no feature selection)

ğŸ“Œ Use when **all features contribute to output**.

---

# ğŸ”¹ Lasso Regression (L1 Regularization)

> **â€œShrink some coefficients to zero â€” automatic feature selection.â€**

Lasso penalizes the absolute value of weights:

\[
Loss = MSE + \lambda \sum |w|
\]

- Can make some coefficients **exactly zero**
- Works like built-in feature selection

âœ… Prevents overfitting  
âœ… Removes unimportant features  
âœ… Useful when dataset has many features

ğŸ“Œ Use when you want **feature selection**.

---

##  Ridge vs Lasso (Summary)

| Feature / Behavior      | Ridge (L2)                     | Lasso (L1)                         |
|------------------------|----------------------------------|-------------------------------------|
| Shrinks coefficients   | âœ… Yes                          | âœ… Yes                              |
| Can set coefficients to zero | âŒ No                     | âœ… Yes (Feature selection)          |
| Best use case          | When many features matter        | When feature selection is needed    |

---

